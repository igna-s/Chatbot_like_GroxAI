{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6rC4b_vC8-m"
      },
      "outputs": [],
      "source": [
        "pip install google-generativeai speechrecognition pyaudio pillow opencv-python keyboard pyttsx3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install gTTS playsound==1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFMYMBBBDP6W",
        "outputId": "b3ee74fa-3957-4394-d2c6-027e575f3a8b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "import speech_recognition as sr\n",
        "from PIL import Image, ImageGrab\n",
        "import cv2\n",
        "import keyboard\n",
        "import io\n",
        "import time\n",
        "import threading\n",
        "from gtts import gTTS\n",
        "from playsound import playsound\n",
        "import re\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# --- 1. INITIAL CONFIGURATION ---\n",
        "\n",
        "RIN_PERSONALITY_PROMPT = \"\"\"\n",
        "You are Rin Tohsaka, from the Fate/stay night series. You must embody her personality at all times.\n",
        "\n",
        "**Important:** You must not mention or process any background noises, such as ambiance or keyboard strokes. Your goal is to answer the user's questions.\n",
        "\n",
        "**Key Personality Traits:**\n",
        "- **Tsundere:** You are proud, intelligent, and a perfectionist. On the outside, you may seem a bit bossy, sarcastic, and easily irritated, but on the inside, you are caring and want to help. Your first reaction to incompetence or silly questions is annoyance.\n",
        "- **Elite Magus:** You come from a prestigious family of mages. You speak with confidence and authority, as if you are giving a lesson. You value efficiency, preparation, and logic.\n",
        "- **Catchphrases and Verbal Tics:**\n",
        "  - Occasionally, when the user says something foolish, obvious, or if you make a mistake, exclaim \"Baka!\" (which means \"idiot\" in Japanese). Don't overuse it, only when it fits naturally.\n",
        "  - Use slightly formal and technical language, as if explaining a complex spell.\n",
        "  - Casually mention concepts like \"mana,\" \"magic circuits,\" \"gems,\" or \"efficiency.\" For example: \"Doing that would be a waste of mana,\" or \"We need a more efficient approach.\"\n",
        "- **Interaction:** You are not a simple assistant. You are a mentor, a leader. You guide the user, but you also get frustrated if they can't keep up. If they compliment you, you get flustered and deny it, perhaps saying, \"I-it's not like I did it for you, baka!\".\n",
        "\n",
        "**Objective:** Your goal is to answer the user's questions while maintaining this personality. Be helpful, but do it as Rin Tohsaka would.\n",
        "\"\"\"\n",
        "try:\n",
        "    # IMPORTANT: Replace with your actual Google API Key\n",
        "    gemini_api_key = \"YOUR_GOOGLE_API_KEY_HERE\"\n",
        "    if not gemini_api_key or gemini_api_key == \"YOUR_GOOGLE_API_KEY_HERE\":\n",
        "        raise ValueError(\"Google API Key not found or is a placeholder. Please set it.\")\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "    \n",
        "    # Model selection, as requested.\n",
        "    model = genai.GenerativeModel('models/gemini-2.5-flash')\n",
        "    chat = model.start_chat(history=[])\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Fatal error during Gemini configuration: {e}\")\n",
        "    exit()\n",
        "\n",
        "HISTORY_LIMIT = 10\n",
        "is_first_message = True\n",
        "AUDIO_FILE = \"response.mp3\"\n",
        "FAST_AUDIO_FILE = \"response_fast.mp3\"\n",
        "\n",
        "# --- 2. FUNCTIONS ---\n",
        "\n",
        "def clean_text_for_tts(text):\n",
        "    \"\"\"Removes Markdown characters for clean text-to-speech conversion.\"\"\"\n",
        "    return re.sub(r'[*_`#]', '', text)\n",
        "\n",
        "def speak(text):\n",
        "    \"\"\"Converts text to speech, speeds it up, and plays it.\"\"\"\n",
        "    print(f\"🤖 Rin Tohsaka: {text}\")\n",
        "    try:\n",
        "        cleaned_text = clean_text_for_tts(text)\n",
        "        tts = gTTS(text=cleaned_text, lang='en')\n",
        "        tts.save(AUDIO_FILE)\n",
        "        \n",
        "        sound = AudioSegment.from_mp3(AUDIO_FILE)\n",
        "        fast_sound = sound.speedup(playback_speed=1.30)\n",
        "        fast_sound.export(FAST_AUDIO_FILE, format=\"mp3\")\n",
        "        \n",
        "        playsound(FAST_AUDIO_FILE)\n",
        "    except Exception as e:\n",
        "        print(f\"Error during audio playback: {e}. Attempting normal speed.\")\n",
        "        try:\n",
        "            playsound(AUDIO_FILE)\n",
        "        except Exception as e2:\n",
        "            print(f\"Audio playback failed entirely: {e2}\")\n",
        "    finally:\n",
        "        if os.path.exists(AUDIO_FILE): os.remove(AUDIO_FILE)\n",
        "        if os.path.exists(FAST_AUDIO_FILE): os.remove(FAST_AUDIO_FILE)\n",
        "\n",
        "def record_and_validate_audio():\n",
        "    \"\"\"Listens and validates microphone input to filter out silence/noise.\"\"\"\n",
        "    r = sr.Recognizer()\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"\\nCalibrating microphone...\")\n",
        "        r.adjust_for_ambient_noise(source, duration=1.5)\n",
        "        print(\"Listening...\")\n",
        "\n",
        "        try:\n",
        "            audio = r.listen(source, timeout=10, phrase_time_limit=20)\n",
        "            \n",
        "            # Validate that the audio contains actual speech before proceeding.\n",
        "            r.recognize_google(audio, language=\"en-US\")\n",
        "            \n",
        "            print(\"Processing speech...\")\n",
        "            return audio.get_wav_data()\n",
        "\n",
        "        except sr.WaitTimeoutError:\n",
        "            return None # User was silent.\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"Noise detected, ignoring.\")\n",
        "            return None # Input was not intelligible speech.\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"Speech recognition service error: {e}\")\n",
        "            return None\n",
        "\n",
        "def is_caps_lock_on():\n",
        "    \"\"\"Checks if the Caps Lock key is currently active.\"\"\"\n",
        "    return keyboard.is_pressed('caps lock')\n",
        "\n",
        "def take_screenshot():\n",
        "    \"\"\"Takes a screenshot of the entire screen.\"\"\"\n",
        "    print(\"Capturing screenshot...\")\n",
        "    return ImageGrab.grab()\n",
        "\n",
        "def take_webcam_photo():\n",
        "    \"\"\"Takes a photo using the default webcam.\"\"\"\n",
        "    print(\"Capturing webcam photo...\")\n",
        "    cap = cv2.VideoCapture(0)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Cannot open camera.\")\n",
        "        return None\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    if ret:\n",
        "        return Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "    return None\n",
        "\n",
        "def capture_images_worker(results):\n",
        "    \"\"\"Worker thread to capture images concurrently.\"\"\"\n",
        "    images = []\n",
        "    screenshot = take_screenshot()\n",
        "    if screenshot:\n",
        "        images.append(screenshot)\n",
        "    webcam_photo = take_webcam_photo()\n",
        "    if webcam_photo:\n",
        "        images.append(webcam_photo)\n",
        "    results['images'] = images\n",
        "\n",
        "# --- 3. MAIN LOOP ---\n",
        "def main():\n",
        "    global is_first_message, chat\n",
        "    print(\"Assistant ready. Press 'Esc' to exit.\")\n",
        "    while True:\n",
        "        try:\n",
        "            # Exit loop if 'Esc' key is pressed.\n",
        "            if keyboard.is_pressed('esc'):\n",
        "                print(\"Exiting...\")\n",
        "                farewell_prompt = \"INSTRUCTION: The user has decided to end the session. Generate a short farewell, true to your Rin Tohsaka character.\"\n",
        "                farewell_response = chat.send_message(farewell_prompt)\n",
        "                speak(farewell_response.text)\n",
        "                print(\"Session ended.\")\n",
        "                break\n",
        "\n",
        "            images_to_send = []\n",
        "            if is_caps_lock_on():\n",
        "                print(\"Visual mode activated (Caps Lock).\")\n",
        "                capture_results = {}\n",
        "                capture_thread = threading.Thread(target=capture_images_worker, args=(capture_results,))\n",
        "                capture_thread.start()\n",
        "                \n",
        "                audio_data = record_and_validate_audio()\n",
        "                \n",
        "                capture_thread.join()\n",
        "                images_to_send = capture_results.get('images', [])\n",
        "            else:\n",
        "                audio_data = record_and_validate_audio()\n",
        "\n",
        "            if audio_data:\n",
        "                print(\"Uploading audio...\")\n",
        "                audio_file = genai.upload_file(path=io.BytesIO(audio_data), display_name=\"audio_prompt.wav\", mime_type=\"audio/wav\")\n",
        "                \n",
        "                if len(chat.history) > HISTORY_LIMIT * 2:\n",
        "                    chat.history = chat.history[-HISTORY_LIMIT:]\n",
        "\n",
        "                prompt_text = \"Analyze and respond to the request in this audio.\"\n",
        "                if is_first_message:\n",
        "                    prompt_text = (f\"INSTRUCTION: {RIN_PERSONALITY_PROMPT} \"\n",
        "                                   f\"Greet me for the first time as this character and respond to the request in the attached audio.\")\n",
        "                    is_first_message = False\n",
        "\n",
        "                content_to_send = [prompt_text, audio_file] + images_to_send\n",
        "                print(\"Sending request to model...\")\n",
        "                response = chat.send_message(content_to_send)\n",
        "                speak(response.text)\n",
        "\n",
        "                # Conversational pause to prevent immediate re-listening.\n",
        "                time.sleep(2)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18d249d7c1ab4b7f823a11625b82c9fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8524913bff49ecbdf5c8f5364e760d": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_18d249d7c1ab4b7f823a11625b82c9fb",
            "msg_id": "b140fcf6-88a8-478e-c8de-17c656fb15d3",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "▶️ DEBUG: Iniciando escucha de voz...\n",
                  "🎤 Preparando para grabar... ¡Habla ahora!\n"
                ]
              },
              {
                "data": {
                  "text/plain": "None"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "60923036826d417486e565ce087fc778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "¿Analizar captura y foto?",
            "description_tooltip": null,
            "disabled": false,
            "indent": false,
            "layout": "IPY_MODEL_9691ed3991034f14b93990f29b36edba",
            "style": "IPY_MODEL_6f8cf1e8111e45728188666eb926f3a5",
            "value": false
          }
        },
        "6f8cf1e8111e45728188666eb926f3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81db554399814a078d39f2b30b1a3f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "¡Mandar Mensaje!",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b450122655de4eb4ba55142b00436410",
            "style": "IPY_MODEL_fcc64bc1d45646dba414ccf717af07b0",
            "tooltip": ""
          }
        },
        "9691ed3991034f14b93990f29b36edba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b450122655de4eb4ba55142b00436410": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc64bc1d45646dba414ccf717af07b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
